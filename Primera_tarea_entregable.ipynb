{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1Tarea.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Para la realización de la primera tarea se estará recreando el material otorgado por el profesor Montenegro para que funcione con GPUs y TPUs. En un inicio debemos asegurarnos que estaremos trabajando primero con CPUs, por lo tanto toca acceder a Runtime > Change runtime type > verificar que la opción seleccionada sea \"None\", esta es la opción para trabajar con CPUs en Google Colab."
      ],
      "metadata": {
        "id": "i9SM70Q68kF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empezamos con una función para leer los datos."
      ],
      "metadata": {
        "id": "qPDeaqaV7THa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os #para interactuar con funcionalidades del sistema operativo\n",
        "import gzip #comprime y descomprime archivos .zip\n",
        "\n",
        "\n",
        "def cargarset(ruta, tipo='train'):\n",
        "  ruta_categorias = os.path.join(ruta, '%s-labels-idx1-ubyte.gz' % tipo)\n",
        "  ruta_imagenes = os.path.join(ruta, '%s-images-idx3-ubyte.gz' % tipo)\n",
        "\n",
        "  with gzip.open(ruta_categorias, 'rb') as rutacate:\n",
        "    etiquetas = np.frombuffer(rutacate.read(), dtype=np.uint8, offset=8)\n",
        "    \n",
        "  with gzip.open(ruta_imagenes, 'rb') as rutaimg:\n",
        "    imagenes = np.frombuffer(rutaimg.read(), dtype=np.uint8, offset=16).reshape(len(etiquetas), 784)\n",
        "\n",
        "  return imagenes, etiquetas"
      ],
      "metadata": {
        "id": "UHfXHACg9Es2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, para poder trabajar con nuestro drive, debemos \"montarlo\", para eso usaremos un servidor remoto de Google Colab. Para poder recrear este ejercicio, con anterioridad debimos haber cargado los archivos encontrados en https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion en una carpeta de nuestro drive."
      ],
      "metadata": {
        "id": "aOuVLCTe9bFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "ruta = 'gdrive/My Drive/TopicosIA/fashion_mnist_data'\n",
        "\n",
        "#guardamos lo que retorna nuestra función definida en un inicio, en este caso \"cargarset\"\n",
        "X_train, Y_train = cargarset(ruta, tipo='train')\n",
        "X_test, Y_test = cargarset(ruta, tipo='test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSHDNV6H_dOa",
        "outputId": "b1f22c08-ec9e-498f-cdfb-aa93fb7094c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, antes de crear el modelo, debemos garantizar que el set de entrenamiento tenga de tamaño un múltiplo de 128, es decir, se reajustarán los datos."
      ],
      "metadata": {
        "id": "_y3NbfBLA83n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[0:59904,:]\n",
        "X_test = X_test[0:9984,:]\n",
        "Y_train = Y_train[0:59904]\n",
        "Y_test = Y_test[0:9984]\n",
        "\n",
        "X_train = np.reshape(X_train,(59904,28,28,1)) #usaremos reshape para asegurarnos que los datos serán imágenes en escala de grises de 28 * 278 píxeles\n",
        "X_test = np.reshape(X_test,(9984,28,28,1))"
      ],
      "metadata": {
        "id": "UQAoJ2Rh_epP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez reajustados los datos, podemos proceder a importar Tensorflow en su segunda versión, que además ya incluye a Keras. \n",
        "Keras es una biblioteca de Python minimalista para Deep Learning que puede funcionar sobre Theano o TensorFlow. Fue desarrollada con el objetivo de que los modelos de Deep Learning sean tan rápidos y fáciles tanto para la investigación como el desarrollo. https://unipython.com/introduccion-y-como-instalar-keras-anaconda/"
      ],
      "metadata": {
        "id": "LKf0L7aOBodq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf\n",
        "print('Versión de TensorFlow: ' + tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tRelDrpB-JC",
        "outputId": "85923b91-af43-4cb6-ae3d-e78577678804"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versión de TensorFlow: 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez ya con TensroFlow, procedemos a importar la librerpia Keras. Primero se crea un contenedor del modelo con sequential, y luego se agregan las tres capas convolucionales. La diferencia entre estas 3 capas son su cantidad de filtros."
      ],
      "metadata": {
        "id": "w15pg7HqCFin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = tf.keras.models.Sequential()\n",
        "modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "modelo.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu')) #64 filtros\n",
        "modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "modelo.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu')) #128 filtros\n",
        "modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "modelo.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu')) #256 filtros\n",
        "modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "modelo.add(tf.keras.layers.Dropout(0.25))"
      ],
      "metadata": {
        "id": "u-nmFGLZCRNy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de estas tres capas vamos a aplanar los datos y agregaremos una red neuronal."
      ],
      "metadata": {
        "id": "QtE6fYvjCbYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.add(tf.keras.layers.Flatten())\n",
        "modelo.add(tf.keras.layers.Dense(256)) #inicio con 256 neuronas\n",
        "modelo.add(tf.keras.layers.Activation('elu'))\n",
        "modelo.add(tf.keras.layers.Dropout(0.5))\n",
        "modelo.add(tf.keras.layers.Dense(10)) #salida con 10 neuronas\n",
        "modelo.add(tf.keras.layers.Activation('softmax'))"
      ],
      "metadata": {
        "id": "sFdDx5cDCfUe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, se puede imprimir la información del modelo en la pantalla, un summary"
      ],
      "metadata": {
        "id": "or8awxsoHO8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ORdX2WdHPx2",
        "outputId": "7127b001-9e50-47e2-d7b8-3c470fd7a565"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (BatchN  (None, 28, 28, 1)        4         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 256)         819456    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               590080    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes del entrenamiento vamos a definir el optimizador a usar, la funcion de error y la metrica de desempeño."
      ],
      "metadata": {
        "id": "f5W_aSZHFKJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HiWDuktkFGo6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento con CPU."
      ],
      "metadata": {
        "id": "24mo1lQAHWLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit #usaremos timeit para almacenar el tiempo de ejecución de cada iteración.\n",
        "\n",
        "def entrenamiento_cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    modelo.fit(X_train,Y_train,validation_data=(X_test,Y_test),batch_size=128,epochs=2,verbose=1) #set de entrenamiento, set de validación, tamaño del lote, número de iteraciones\n",
        "  \n",
        "  return None\n",
        "\n",
        "cpu_time = timeit.timeit('entrenamiento_cpu()', number=1, setup='from __main__ import entrenamiento_cpu') #almacenando el tiempo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBh6mI5oIUM_",
        "outputId": "a871cfb9-7258-45b3-8114-ac3d29d86fb2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "468/468 [==============================] - 658s 1s/step - loss: 0.6730 - accuracy: 0.7825 - val_loss: 0.3805 - val_accuracy: 0.8632\n",
            "Epoch 2/2\n",
            "468/468 [==============================] - 716s 2s/step - loss: 0.3896 - accuracy: 0.8630 - val_loss: 0.3457 - val_accuracy: 0.8791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tiempo de entrenamiento ' + str(cpu_time)+ ' segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKON4thJIvGq",
        "outputId": "c01cb10d-7703-4bf5-d1d2-7b52cbc910e9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento 1402.8152854450004 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento con GPU"
      ],
      "metadata": {
        "id": "jkxsvM9zTBzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este entrenamiento tenemos que tener en cuenta que toca acceder a Runtime > Change runtime type > seleccionar GPU > guardar. Además, toca correr de nuevo todo el código hasta la definición del optimizador a usar."
      ],
      "metadata": {
        "id": "P2M5JeqQTJuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit #usaremos timeit para almacenar el tiempo de ejecución de cada iteración.\n",
        "\n",
        "def entrenamiento_gpu():\n",
        "  with tf.device('/gpu:0'):\n",
        "    modelo.fit(X_train,Y_train,validation_data=(X_test,Y_test),batch_size=128,epochs=2,verbose=1) #set de entrenamiento, set de validación, tamaño del lote, número de iteraciones\n",
        "  \n",
        "  return None\n",
        "\n",
        "gpu_time = timeit.timeit('entrenamiento_gpu()', number=1, setup='from __main__ import entrenamiento_gpu') #almacenando el tiempo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QerLYud7Tpmi",
        "outputId": "f66c0bfe-d0e2-470b-bc3b-495bd01e5451"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "468/468 [==============================] - 29s 40ms/step - loss: 0.6825 - accuracy: 0.7824 - val_loss: 0.3737 - val_accuracy: 0.8707\n",
            "Epoch 2/2\n",
            "468/468 [==============================] - 19s 40ms/step - loss: 0.3917 - accuracy: 0.8629 - val_loss: 0.3423 - val_accuracy: 0.8732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tiempo de entrenamiento ' + str(gpu_time)+ ' segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikL6DJT-VOxF",
        "outputId": "9a4f067d-ea7c-40f3-91a8-088336626e90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento 82.99002373799999 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento con TPU"
      ],
      "metadata": {
        "id": "isgWXc5EVVQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para el entrenamiento con TPUs toca ir a Runtime > Change runtime type > seleccionar TPU, pero además toca reconocer la TPU, conectarse a esta, inicializarla y crear un objeto donde almacenaremos el modelo a entrenar. Cabe resaltar que antes de todo esto, de nuevo toca correr todo el código hasta de nuevo, la selección del optimizador."
      ],
      "metadata": {
        "id": "HRG_TBeFWNkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])  # Detectar TPU\n",
        "  print('TPU encontrada ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: TPU no encontrada!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0cVWfQxaP3A",
        "outputId": "cfda57da-ab7d-4fab-d81f-2c8c8d48ec18"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU encontrada  ['10.16.150.122:8470']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental_connect_to_cluster(tpu) #conectar\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu) #inicializar\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu) #crear el objeto para poder correr el modelo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S3XCjX_Z8Lg",
        "outputId": "9bf4b973-d237-4f81-af72-18fc10a029c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.150.122:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.150.122:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, ya contando con la TPU reconocida, conectada, inicializada y creado tpu strategy, vamos a almacenar el modelo dentro de un with"
      ],
      "metadata": {
        "id": "GCTEunhYaXwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tpu_strategy.scope():\n",
        "  modelo = tf.keras.models.Sequential()\n",
        "  modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "  modelo.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "  modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "  modelo.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "  modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "  modelo.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "  modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  modelo.add(tf.keras.layers.Flatten())\n",
        "  modelo.add(tf.keras.layers.Dense(256))\n",
        "  modelo.add(tf.keras.layers.Activation('elu'))\n",
        "  modelo.add(tf.keras.layers.Dropout(0.5))\n",
        "  modelo.add(tf.keras.layers.Dense(10))\n",
        "  modelo.add(tf.keras.layers.Activation('softmax'))\n",
        "  modelo.summary()\n",
        "\n",
        "  modelo.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy']) #definimos optimizador, funcion de error y la métrica"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJufMQC1at3z",
        "outputId": "9ad2e443-4569-4fa0-80e4-8088f1582a3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_3 (Batc  (None, 28, 28, 1)        4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 256)         819456    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               590080    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, para proceder con el entrenamiento, convertiremos los datos a formato punto flotante de 32 bits, pues es el requerido por Google Colab para usar entrenamientos con TPUs. Una vez con esa transformación, procedemos a correr el entrenamiento."
      ],
      "metadata": {
        "id": "tRA5lqa7bAz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "x_train = X_train.astype(np.float32)\n",
        "y_train = Y_train.astype(np.float32)\n",
        "x_test = X_test.astype(np.float32)\n",
        "y_test = Y_test.astype(np.float32)\n",
        "\n",
        "def entrenamiento_tpu():\n",
        "  modelo.fit(x_train,y_train,validation_data=(x_test,y_test), batch_size=128, epochs=2, verbose=1)\n",
        "  \n",
        "  return None\n",
        "\n",
        "tpu_time = timeit.timeit('entrenamiento_tpu()', number=1, setup='from __main__ import entrenamiento_tpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKEo9RHXVbAa",
        "outputId": "b80b249c-94a6-4c12-e758-1315e1073484"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "468/468 [==============================] - 16s 23ms/step - loss: 0.7199 - accuracy: 0.7760 - val_loss: 0.3866 - val_accuracy: 0.8648\n",
            "Epoch 2/2\n",
            "468/468 [==============================] - 9s 20ms/step - loss: 0.4023 - accuracy: 0.8583 - val_loss: 0.3077 - val_accuracy: 0.8877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tiempo con TPU: ' + str(tpu_time) + ' segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwBu-OaRbk0-",
        "outputId": "ac332637-0677-4f78-c2c5-65bec60ce0e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo con TPU: 28.522188180000285 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusión:"
      ],
      "metadata": {
        "id": "QeK_bQACbog1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos ver, hay diferencias significativas entre el uso de CPU para entrenamientos (en este caso, fueron 24 minutos de entrenamiento) y el uso de GPU, siendo cuestión de un poco más de un minuto el tiempo necesario para el entrenamiento, y por último con el uso de TPU es un poco menos que medio minuto, aunque es más laborioso de usar este método a comparación de la GPU."
      ],
      "metadata": {
        "id": "CjzlaeDIbsnU"
      }
    }
  ]
}
