{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PrimeraTarea.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Para la realización de la primera tarea se estará recreando los ejercicios propuestos en el vídeo tutorial de \"Codificando Bits\" encontrado en el siguiente link https://www.youtube.com/watch?v=0mOV4plF2Xo\\"
      ],
      "metadata": {
        "id": "6eA2E46eaJxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función para leer el conjunto de datos: Un función que permita cargar los datos de entrenamiento y validación, junto a sus categorías correspondientes."
      ],
      "metadata": {
        "id": "XDgnEWjPaPiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os #para interactuar con funcionalidades del sistema operativo\n",
        "import gzip #comprime y descomprime archivos .zip\n",
        "\n",
        "\n",
        "def cargarset(ruta, tipo='train'):\n",
        "  ruta_categorias = os.path.join(ruta, '%s-labels-idx1-ubyte.gz' % tipo)\n",
        "  ruta_imagenes = os.path.join(ruta, '%s-images-idx3-ubyte.gz' % tipo)\n",
        "\n",
        "  with gzip.open(ruta_categorias, 'rb') as rutacate:\n",
        "    etiquetas = np.frombuffer(rutacate.read(), dtype=np.uint8, offset=8)\n",
        "    \n",
        "  with gzip.open(ruta_imagenes, 'rb') as rutaimg:\n",
        "    imagenes = np.frombuffer(rutaimg.read(), dtype=np.uint8, offset=16).reshape(len(etiquetas), 784)\n",
        "\n",
        "  return imagenes, etiquetas"
      ],
      "metadata": {
        "id": "iMOeQod9aMRM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al presionar Shift+Enter o el ícono de un triángulo al lado del bloque de código, esto correrá el bloque en una de las CPUs disponibles en Google Collab.\n",
        "\n",
        "Ahora, vamos a montar el drive en el servidor remoto de Google Colab para trabajar con los datos en nuestro Drive."
      ],
      "metadata": {
        "id": "zSBTOcceaaoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzDh5oX6cNdj",
        "outputId": "4782289a-0ccd-43a8-bb81-4bc68e7a1c6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ruta = 'gdrive/My Drive/TopicosIA/fashion_mnist_data'\n",
        "\n",
        "X_train, Y_train = cargarset(ruta, tipo='train')\n",
        "X_test, Y_test = cargarset(ruta, tipo='test')"
      ],
      "metadata": {
        "id": "6Htv1_D2miY2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, antes de crear el modelo, debemos garantizar que el set de entrenamiento tenga de tamaño un múltiplo de 128, es decir, se reajustarán los datos. \n",
        "\n",
        "También usaremos reshape para asegurarnos que los datos serán imágenes en escala de grises de 28 * 278 píxeles"
      ],
      "metadata": {
        "id": "TzCkHSd8c6tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[0:59904,:]\n",
        "X_test = X_test[0:9984,:]\n",
        "Y_train = Y_train[0:59904]\n",
        "Y_test = Y_test[0:9984]\n",
        "\n",
        "X_train = np.reshape(X_train,(59904,28,28,1))\n",
        "X_test = np.reshape(X_test,(9984,28,28,1))"
      ],
      "metadata": {
        "id": "btHlFXXydSbj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, para empezar con el modelo, primero debemos importar TensorFlow en su segunda versión"
      ],
      "metadata": {
        "id": "cLUKpYfudvC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf\n",
        "print('Versión de TensorFlow: ' + tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08Ia_qbDduqa",
        "outputId": "759b810c-bc7e-474f-8139-f654378626c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versión de TensorFlow: 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, una vez con TensorFlow2, vamos a importar la libería Keras:\n",
        "\n",
        "Keras es una biblioteca de Python minimalista para Deep Learning que puede funcionar sobre Theano o TensorFlow. Fue desarrollada con el objetivo de que los modelos de Deep Learning sean tan rápidos y fáciles tanto para la investigación como el desarrollo. https://unipython.com/introduccion-y-como-instalar-keras-anaconda/"
      ],
      "metadata": {
        "id": "jUq0GVxJeu-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se crea un contenedor del modelo con sequential, y luego se agregan las tres capas convolucionales. La diferencia entre estas 3 capas son su cantidad de filtros."
      ],
      "metadata": {
        "id": "-tdbiE_GfAWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = tf.keras.models.Sequential()\n",
        "modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "modelo.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu')) #64 filtros\n",
        "modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "modelo.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu')) #128 filtros\n",
        "modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "modelo.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu')) #256 filtros\n",
        "modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "modelo.add(tf.keras.layers.Dropout(0.25))"
      ],
      "metadata": {
        "id": "pPIB98ihe5Ap"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Después de estas tres capas vamos a aplanar los datos y agregaremos una red neuronal "
      ],
      "metadata": {
        "id": "W-k5cZXSgFUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.add(tf.keras.layers.Flatten())\n",
        "modelo.add(tf.keras.layers.Dense(256)) #inicio con 256 neuronas\n",
        "modelo.add(tf.keras.layers.Activation('elu'))\n",
        "modelo.add(tf.keras.layers.Dropout(0.5))\n",
        "modelo.add(tf.keras.layers.Dense(10)) #salida con 10 neuronas\n",
        "modelo.add(tf.keras.layers.Activation('softmax'))"
      ],
      "metadata": {
        "id": "wSiDVTH7gPwH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, se puede imprimir la información del modelo en la pantalla, un summary"
      ],
      "metadata": {
        "id": "s6KES7uahvNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYaxOUyZhy6Z",
        "outputId": "91ff69b1-6fb0-470b-f9a7-8b51d94dd320"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (BatchN  (None, 28, 28, 1)        4         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 256)         819456    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               590080    \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NRfoPhmOiEL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes del entrenamiento vamos a definir el optimizador a usar, la funcion de error y la metrica de desempeño."
      ],
      "metadata": {
        "id": "TMkWbUtqoyS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8-wmL9sApH1z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento con CPU!\n",
        "\n",
        "Al ser una red convolucional compleja que tiene Total params: 1,619,470\n",
        "Trainable params: 1,619,084, el tiempo de procesamiento será muy lento, así que las iteraciones serán solo 2.\n",
        "\n",
        "Queremos comparar el rendimiento entre CPU, GPU y TPU, así que usaremos timeit para almacenar el tiempo de ejecución de cada iteración."
      ],
      "metadata": {
        "id": "qoAHeA3wpgbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def entrenamiento_cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    modelo.fit(X_train,Y_train,validation_data=(X_test,Y_test),batch_size=128,epochs=2,verbose=1) #set de entrenamiento, set de validación, tamaño del lote, número de iteraciones\n",
        "  \n",
        "  return None\n",
        "\n",
        "cpu_time = timeit.timeit('entrenamiento_cpu()', number=1, setup='from __main__ import entrenamiento_cpu') #almacenando el tiempo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICsF1KekpZRV",
        "outputId": "71542525-7600-4d69-9893-c8c5f2d3fbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "468/468 [==============================] - 809s 2s/step - loss: 0.6795 - accuracy: 0.7832 - val_loss: 0.3936 - val_accuracy: 0.8604\n",
            "Epoch 2/2\n",
            "468/468 [==============================] - 845s 2s/step - loss: 0.3922 - accuracy: 0.8611 - val_loss: 0.3333 - val_accuracy: 0.8853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tiempo con CPU: ' + str(cpu_time) + ' segundos')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0rcomCgrS-o",
        "outputId": "391c2023-5820-45b8-c809-2cbf84a3d4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo con CPU: 1653.8483386400003 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El entrenamiento con CPU tardó un total de "
      ],
      "metadata": {
        "id": "qT6PYSBhrA1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento con GPU!\n",
        "Entrenaremos el mismo modelo pero cambiando la arquitactura.\n",
        "\n",
        "\n",
        "*   En Hardware acceleration seleccionaremos GPU, en el anterior entrenamiento teníamos seleccionada la opción \"none\".\n",
        "*   Verificaremos la disponibilidad de la GPU asignada por Google Colab para verificar que la GPU esté disponible para el entrenamiento.\n",
        "\n",
        "*   Para este paso no solo basta cambiar de CPU a GPU, también es bueno volver a \"llamar\" a tensorflow, o mejor aún, todo el código volverlo a correr a excepción del entrenamiento con CPU\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w1FymHdorF9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nombre_gpu = tf.test.gpu_device_name()\n",
        "if nombre_gpu != '/device:GPU:0':\n",
        "  raise SystemError('GPU no encontrada')\n",
        "print('GPU encontrada: {}'.format(nombre_gpu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd3QsyBJq_5x",
        "outputId": "e9560de9-85a1-4e7b-a60d-dc4ebdd79124"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU encontrada: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, verificado esto, procederemos con el entrenamiento."
      ],
      "metadata": {
        "id": "E399XG98sMrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def entrenamiento_gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    modelo.fit(X_train,Y_train,validation_data=(X_test,Y_test),batch_size=128,epochs=2,verbose=1) #set de entrenamiento, set de validación, tamaño del lote, número de iteraciones\n",
        "  \n",
        "  \n",
        "  return None\n",
        "\n",
        "gpu_time = timeit.timeit('entrenamiento_gpu()', number=1, setup='from __main__ import entrenamiento_gpu') #almacenando el tiempo usado"
      ],
      "metadata": {
        "id": "Ki9R1y8UsQcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b21c97cf-8a5e-41f3-fdee-ec0b32562664"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "468/468 [==============================] - 28s 39ms/step - loss: 0.7053 - accuracy: 0.7747 - val_loss: 0.3901 - val_accuracy: 0.8540\n",
            "Epoch 2/2\n",
            "468/468 [==============================] - 19s 40ms/step - loss: 0.3944 - accuracy: 0.8624 - val_loss: 0.3122 - val_accuracy: 0.8882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A diferencia del entrenamiento con la CPU, la GPU resultó ser mucho más óptima, pues fue mucho más rápida con un tiempo menor a un minuto, mucho menor que los 26 minutos que s enecesitaron con la CPU."
      ],
      "metadata": {
        "id": "3p88Lrb6shGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tiempo con GPU: ' + str(gpu_time) + ' segundos')"
      ],
      "metadata": {
        "id": "LZdmMLILs4-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994dbebe-45f5-4a23-ca07-e2fb1452cd6c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo con GPU: 47.23649320699997 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, hagamos el entrenamiento con una TPU!\n",
        "\n",
        "\n",
        "*   Debemos verificar que en el hardware accelerator esté seleccionado la TPU\n",
        "*   Ahora detectaremos la TPU y además usaremos algunas funciones de tensorflow para conectarnos a esta, inicializarla y crear un objeto para así lograr crear y compilar el modelo.\n",
        "\n",
        "*   Para el entrenamiento con la TPU también es necesario correr d enuevo todo a excepción de los entrenamientos con CPU y TPU.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pkpOn4_wtA6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])  # Detectar TPU\n",
        "  print('TPU encontrada ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: TPU no encontrada!')"
      ],
      "metadata": {
        "id": "mZCOEovNtzzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74009b47-d8e4-4ad5-8359-b8910c72ddf5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU encontrada  ['10.68.78.98:8470']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos proceder a conectarnos a la TPU e inicializarla"
      ],
      "metadata": {
        "id": "TicOfm4Ft5I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental_connect_to_cluster(tpu) #conectar\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu) #inicializar\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu) #crear el objeto para poder correr el modelo"
      ],
      "metadata": {
        "id": "GfVcujaluDDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f016b622-2d4d-43e2-cf70-899fd98d7492"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.68.78.98:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.68.78.98:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copiamos las líneas del modelo pero dentro de un with "
      ],
      "metadata": {
        "id": "-1-c4efoubc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "garQyxxYdWbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tpu_strategy.scope():\n",
        "  modelo = tf.keras.models.Sequential()\n",
        "  modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "  modelo.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "  modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "  modelo.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "  modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  modelo.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "  modelo.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "  modelo.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  modelo.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "  modelo.add(tf.keras.layers.Flatten())\n",
        "  modelo.add(tf.keras.layers.Dense(256))\n",
        "  modelo.add(tf.keras.layers.Activation('elu'))\n",
        "  modelo.add(tf.keras.layers.Dropout(0.5))\n",
        "  modelo.add(tf.keras.layers.Dense(10))\n",
        "  modelo.add(tf.keras.layers.Activation('softmax'))\n",
        "  modelo.summary()\n",
        "\n",
        "  modelo.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xMnFrttTuTpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200cc011-8076-4ca6-c065-67dde4f95ee1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_3 (Batc  (None, 28, 28, 1)        4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 256)         819456    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               590080    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, para proceder con el entrenamiento,  convertiremos los datos a formato punto flotante de 32 bits, pues es el requerido por Google Colab para usar entrenamientos con TPUs."
      ],
      "metadata": {
        "id": "RNK_c-9ivjuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "x_train = X_train.astype(np.float32)\n",
        "y_train = Y_train.astype(np.float32)\n",
        "x_test = X_test.astype(np.float32)\n",
        "y_test = Y_test.astype(np.float32)\n",
        "\n",
        "def entrenamiento_tpu():\n",
        "  modelo.fit(x_train,y_train,validation_data=(x_test,y_test), batch_size=128, epochs=2, verbose=1)\n",
        "  \n",
        "  return None\n",
        "\n",
        "tpu_time = timeit.timeit('entrenamiento_tpu()', number=1, setup='from __main__ import entrenamiento_tpu')"
      ],
      "metadata": {
        "id": "QIRCjEU2vxKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f721ef-7364-47a7-a381-6ee2cb730dbf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "468/468 [==============================] - 15s 21ms/step - loss: 0.6953 - accuracy: 0.7807 - val_loss: 0.3507 - val_accuracy: 0.8718\n",
            "Epoch 2/2\n",
            "468/468 [==============================] - 8s 18ms/step - loss: 0.3966 - accuracy: 0.8601 - val_loss: 0.3022 - val_accuracy: 0.8893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último vemos que el uso de una TPU disminuye significativamente el tiempo del entrenamiento, siendo este de solo 26 segundos, mucho más rápido que los dos anteriores entrenamientos. Con este ejemplo podemos ver cómo lo más óptimo es el uso de TPUs."
      ],
      "metadata": {
        "id": "zbDZo_rAv3FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tiempo con TPU: ' + str(tpu_time) + ' segundos')"
      ],
      "metadata": {
        "id": "yUl-F4jPv_7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92410d47-f6be-44b4-9b8f-d083767d6ff8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo con TPU: 26.58704345299998 segundos\n"
          ]
        }
      ]
    }
  ]
}